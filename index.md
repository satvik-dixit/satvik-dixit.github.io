---
layout: default
---

<div class="intro-section">
  <img src="/assets/img/picture.jpg" alt="Satvik Dixit" class="profile-picture-small">
  <div class="intro-text">

My research focuses on building efficient audio-centric models and evaluation methods for evolving real-world applications and workflows.

I've worked on:
<ul>
<li>Efficient audio-language models (<a href="https://arxiv.org/abs/2503.08540">Mellow</a>) </li>
<li>Evaluation metrics that align with human judgments (<a href="https://arxiv.org/abs/2510.04934">AURA Score</a>, <a href="https://arxiv.org/abs/2411.00321">MACE</a>)</li>
<li>Benchmarks for audio generation and understanding (<a href="https://gclef-cmu.org/foleybench/">FoleyBench</a>, <a href="https://sonalkum.github.io/mmau-pro">MMAU-Pro</a>)</li>
</ul>

Currently, I am a founding engineer at a YC-backed startup working on voice agent evals. Previously, I was a masters student at CMU advised by Professors <a href="https://chrisdonahue.com/">Chris Donahue</a> and <a href="https://cmu-mlsp.github.io/team/bhiksha_raj/">Bhiksha Raj</a>, where I worked on models and evaluation methods for audio-based systems. I have also done research internships at <a href="https://sensein.group/">MIT</a> and <a href="https://www.epfl.ch/labs/lcav/">EPFL</a>. Before that, I did my undergrad in electrical engineering at IIT Delhi.

  </div>
</div>

<div class="main-content-wrapper">
  <div class="sidebar-spacer"></div>
  <div class="content-right">
<div class="news-section">
  <h2>News</h2>
  <ul>
    <li>Nov 2025: <a href="https://gclef-cmu.org/foleybench/">FoleyBench</a> accepted to <strong>ICASSP 2026</strong></li>
    <li>Nov 2025: <a href="https://arxiv.org/abs/2508.13992">MMAU-Pro</a> accepted to <strong>AAAI 2026</strong></li>
    <li>Sept 2025: <a href="https://arxiv.org/abs/2503.08540">Mellow</a> accepted to <strong>NeurIPS 2025</strong></li>
    <li>July 2025: Work on <a href="https://arxiv.org/abs/2506.01588">Morphing</a> accepted to <strong>WASPAA 2025</strong></li>
    <li>Jan 2025: <a href="https://arxiv.org/abs/2411.00321v1">MACE</a> accepted to <strong>ICASSP SALMA 2025</strong></li>
  </ul>
</div>

<h2>Selected Publications and Preprints</h2>
<div class="publication">
  <img src="/assets/img/paper_5.png" alt="Mellow Preview" class="publication-image">
  <div class="publication-content">
    <h4>Mellow: a small audio language model for reasoning</h4>
    <p class="publication-authors">Soham Deshmukh, <strong>Satvik Dixit</strong>, Rita Singh, Bhiksha Raj</p>
    <p class="publication-venue"><strong>NeurIPS 2025</strong></p>
    <div class="publication-links">
      <a href="https://arxiv.org/abs/2503.08540">Paper</a>
      <a href="https://github.com/soham97/mellow">Code</a>
    </div>
  </div>
</div>

<div class="publication">
  <img src="/assets/img/fig.png" alt="FoleyBench Preview" class="publication-image">
  <div class="publication-content">
    <h4>FoleyBench: A Benchmark For Video-to-Audio Models</h4>
    <p class="publication-authors"><strong>Satvik Dixit</strong>, Koichi Saito, Zhi Zhong, Yuki Mitsufuji, Chris Donahue</p>
    <p class="publication-venue">Submitted to <strong>ICASSP 2026</strong></p>
    <div class="publication-links">
      <a href="https://arxiv.org/abs/2511.13219">Paper</a>
      <a href="https://gclef-cmu.org/foleybench/">Page</a>
    </div>
  </div>
</div>

<div class="publication">
  <img src="/assets/img/main_fig.png" alt="AURA Score Preview" class="publication-image">
  <div class="publication-content">
    <h4>AURA Score: A Metric For Holistic Audio Question Answering Evaluation</h4>
    <p class="publication-authors"><strong>Satvik Dixit</strong>, Soham Deshmukh, Bhiksha Raj</p>
    <p class="publication-venue">Submitted to <strong>ICASSP 2026</strong></p>
    <div class="publication-links">
      <a href="https://arxiv.org/abs/2510.04934">Paper</a>
      <a href="https://github.com/satvik-dixit/AURA">Code</a>
    </div>
  </div>
</div>

<div class="publication">
  <img src="/assets/img/paper_3_new.png" alt="Vision Language Models Preview" class="publication-image">
  <div class="publication-content">
    <h4>Vision Language Models Are Few-Shot Audio Spectrogram Classifiers</h4>
    <p class="publication-authors"><strong>Satvik Dixit</strong>, Laurie Heller, Chris Donahue</p>
    <p class="publication-venue"><strong>NeurIPS 2024 Audio Imagination Workshop</strong></p>
    <div class="publication-links">
      <a href="https://openreview.net/pdf?id=RnBAclRKOC">Paper</a>
    </div>
  </div>
</div>

<h2>Contact</h2>
<div class="contact-links">
  <a href="mailto:satvikdixit7@gmail.com">Email</a>
  <a href="https://scholar.google.com/citations?user=UNx0GHAAAAAJ&hl=en">Google Scholar</a>
  <a href="https://www.semanticscholar.org/author/Satvik-Dixit/2222424545">Semantic Scholar</a>
  <a href="https://www.linkedin.com/in/satvik-dixit/">LinkedIn</a>
</div>

  </div>
</div>

<br>
<br>
