---
layout: default
---

I am a master's student at Carnegie Mellon University. I work with Professor [Bhiksha Raj](https://cmu-mlsp.github.io/team/bhiksha_raj) on  Audio Language Models and Professor [Chris Donahue](https://chrisdonahue.com/) on Generative Audio. I am interested in audio understanding and generation.

Previously, I interned with Dr [Satrajit Ghosh](https://sensein.group/) at MIT and Dr [Martin Vetterli](https://www.epfl.ch/labs/lcav/people/martin-vetterli/) at EPFL. I completed my undergraduate degree in Electrical Engineering at IIT Delhi, where my concentration was on signals processing and ML.

## Education

- M.S., Computer Engineering
  - Carnegie Mellon University
  - August 2023 - December 2024 
- B. Tech., Electrical Engineering 
  - Indian Institute of Technology, Delhi
  - August 2019 - August 2023


## Publications and Preprints
<div class="publication">
  <img src="/assets/img/paper_5.png" alt="Mellow Preview" class="publication-image" style="width: 300px;">
  <div class="publication-content">
    <h4>Mellow: a small audio language model for reasoning</h4>
    <p>Soham Deshmukh, <strong>Satvik Dixit</strong>, Rita Singh, Bhiksha Raj</p>
    <ul>
      <li>Under review at NeurIPS 2025</li>
      <li><a href="https://arxiv.org/abs/2503.08540">Paper</a></li>
      <li><a href="https://github.com/soham97/mellow">Code</a></li>
    </ul>
  </div>
</div>
<div class="publication">
  <img src="/assets/img/paper_4.png" alt="MACE Preview" class="publication-image" style="width: 300px;">
  <div class="publication-content">
    <h4>MACE: Leveraging Audio for Evaluating Audio Captioning Systems</h4>
    <p><strong>Satvik Dixit</strong>, Soham Deshmukh, Bhiksha Raj</p>
    <ul>
      <li>ICASSP 2025 Speech and Audio Language Models (SALMA) Workshop</li>
      <li><a href="https://arxiv.org/abs/2411.00321">Paper</a></li>
      <li><a href="https://github.com/satvik-dixit/mace/tree/main">Code</a></li>
    </ul>
  </div>
</div>
<div class="publication">
  <img src="/assets/img/paper_3.png" alt="Vision Language Models Preview" class="publication-image" style="width: 300px;">
  <div class="publication-content">
    <h4>Vision Language Models Are Few-Shot Audio Spectrogram Classifiers</h4>
    <p><strong>Satvik Dixit</strong>, Laurie Heller, Chris Donahue</p>
    <ul>
      <li>NeuRIPS 2024 Audio Imagination Workshop</li>
      <li><a href="https://openreview.net/pdf?id=RnBAclRKOC">Paper</a></li>
    </ul>
  </div>
</div>
<div class="publication">
  <img src="/assets/img/paper_1.png" alt="Speaker Representations Preview" class="publication-image" style="width: 300px;">
  <div class="publication-content">
    <h4>Improving Speaker Representations Using Contrastive Losses on Multi-scale Features</h4>
    <p><strong>Satvik Dixit</strong>, Massa Baali, Rita Singh, Bhiksha Raj</p>
    <ul>
      <li>Preprint</li>
      <li><a href="https://arxiv.org/abs/2410.05037">Paper</a></li>
      <li><a href="https://github.com/satvik-dixit/MFCon/tree/main">Code</a></li>
    </ul>
  </div>
</div>
<div class="publication">
  <img src="/assets/img/paper_2.png" alt="Speech Emotion Recognition Preview" class="publication-image" style="width: 300px;">
  <div class="publication-content">
    <h4>Explaining Deep Learning Embeddings for Speech Emotion Recognition by Predicting Interpretable Acoustic Features</h4>
    <p><strong>Satvik Dixit</strong>, Daniel M. Low, Gasser Elbanna, Fabio Catania, Satrajit S. Ghosh</p>
    <ul>
      <li>Preprint</li>
      <li><a href="https://www.arxiv.org/abs/2409.09511">Paper</a></li>
      <li><a href="https://github.com/satvik-dixit/explainability_SER/tree/main">Code</a></li>
    </ul>
  </div>
</div>
<br>
<br>







 



  






